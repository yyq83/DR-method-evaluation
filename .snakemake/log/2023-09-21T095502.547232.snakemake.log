Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job stats:
job               count    min threads    max threads
--------------  -------  -------------  -------------
run_method_pre        1              1              1
total                 1              1              1

Select jobs to execute...

[Thu Sep 21 09:55:03 2023]
rule run_method_pre:
    input: HGIMC/Datasets/Cdataset.mat
    output: Evaluation/HGIMC_Cdataset.csv
    log: Evaluation/log/HGIMC_Cdataset.log
    jobid: 0
    benchmark: Evaluation/Benchmark/benchmark_HGIMC_Cdataset.txt
    wildcards: outdir=Evaluation, method=HGIMC, dataset=Cdataset
    resources: tmpdir=/tmp

Activating conda environment: /home1/yangyinqi/DR-method-evaluation/.snakemake/conda/5e99b574ec465c2508540992d6c82145
[Thu Sep 21 09:55:19 2023]
Finished job 0.
1 of 1 steps (100%) done
Complete log: /home1/yangyinqi/DR-method-evaluation/.snakemake/log/2023-09-21T095502.547232.snakemake.log
